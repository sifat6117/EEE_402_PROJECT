{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12597901,
          "sourceType": "datasetVersion",
          "datasetId": 7956455
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Fork of Fork of AIML_PROJECT_RUN_1 4cdcc5",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "7rKno4CDr4TZ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "mdwoahidurrahman_figs_braintumor_segmentation_classification_sorted_path = kagglehub.dataset_download('mdwoahidurrahman/figs-braintumor-segmentation-classification-sorted')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "pz1ttTm0r4Tb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np, cv2, os, tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import albumentations as A\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:13:07.671669Z",
          "iopub.execute_input": "2025-08-01T19:13:07.671958Z",
          "iopub.status.idle": "2025-08-01T19:13:26.082664Z",
          "shell.execute_reply.started": "2025-08-01T19:13:07.671926Z",
          "shell.execute_reply": "2025-08-01T19:13:26.081991Z"
        },
        "id": "Z3Y0REkqr4Tc",
        "outputId": "2edaac7b-c505-4a39-acc7-cb4bee9d9708"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-08-01 19:13:09.595657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754075589.788165      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754075589.841242      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_brisc_data(data_dir, split='train'):\n",
        "    \"\"\"\n",
        "    Reads:\n",
        "      <data_dir>/classification_task/{split}/{class}/*.jpg      (e.g. 2948.jpg)\n",
        "      <data_dir>/segmentation_task/{split}/images/*.jpg         (e.g. glioma_2948.jpg)\n",
        "      <data_dir>/segmentation_task/{split}/masks/*.png\n",
        "\n",
        "    Returns a DataFrame with columns:\n",
        "      image_path : full path to the segmentation image\n",
        "      mask_path  : full path to the matching mask\n",
        "      label      : integer 0=glioma,1=meningioma,2=pituitary\n",
        "    \"\"\"\n",
        "\n",
        "    cls_root    = os.path.join(data_dir, 'classification_task', split)\n",
        "    seg_img_dir = os.path.join(data_dir, 'segmentation_task',    split, 'images')\n",
        "    seg_msk_dir = os.path.join(data_dir, 'segmentation_task',    split, 'masks')\n",
        "\n",
        "    # your label map\n",
        "    class_map = {'glioma':0, 'meningioma':1, 'pituitary':2}\n",
        "\n",
        "    records = []\n",
        "    # walk each class folder in classification_task\n",
        "    for cls_name, cls_idx in class_map.items():\n",
        "        cls_folder = os.path.join(cls_root, cls_name)\n",
        "        if not os.path.isdir(cls_folder):\n",
        "            continue\n",
        "\n",
        "        for fname in os.listdir(cls_folder):\n",
        "            if not fname.lower().endswith('.jpg'):\n",
        "                continue\n",
        "\n",
        "            # fname is e.g. \"2948.jpg\"\n",
        "            img_id = os.path.splitext(fname)[0]\n",
        "\n",
        "            # find the segmentation image that ends with _{img_id}.jpg\n",
        "            matches = [f for f in os.listdir(seg_img_dir)\n",
        "                       if f.endswith(f\"_{img_id}.jpg\")]\n",
        "            if not matches:\n",
        "                print(f\"[!] no seg image for {fname}\")\n",
        "                continue\n",
        "\n",
        "            seg_fname = matches[0]                    # e.g. \"glioma_2948.jpg\"\n",
        "            mask_fname = seg_fname.replace('.jpg', '.png')\n",
        "            img_path   = os.path.join(seg_img_dir, seg_fname)\n",
        "            mask_path  = os.path.join(seg_msk_dir, mask_fname)\n",
        "\n",
        "            if not os.path.exists(mask_path):\n",
        "                print(f\"[!] no mask for {seg_fname}\")\n",
        "                continue\n",
        "\n",
        "            records.append({\n",
        "                'image_path': img_path,\n",
        "                'mask_path' : mask_path,\n",
        "                'label'     : cls_idx\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "    if df.empty:\n",
        "        raise RuntimeError(f\"No data found under {data_dir!r} split={split}\")\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:13:26.083613Z",
          "iopub.execute_input": "2025-08-01T19:13:26.084112Z",
          "iopub.status.idle": "2025-08-01T19:13:26.091325Z",
          "shell.execute_reply.started": "2025-08-01T19:13:26.08408Z",
          "shell.execute_reply": "2025-08-01T19:13:26.090634Z"
        },
        "id": "MIO-Y4Izr4Td"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Generator (now reads full paths) ---\n",
        "class MultiTaskDataGenerator(Sequence):\n",
        "    def __init__(self, df, batch_size=8, img_size=(256,256)):\n",
        "        \"\"\"\n",
        "        df : DataFrame with columns ['image_path','mask_path','label']\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size   = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch = self.df.iloc[idx*self.batch_size : (idx+1)*self.batch_size]\n",
        "        X, Y_seg, Y_cls = [], [], []\n",
        "\n",
        "        for _, row in batch.iterrows():\n",
        "            img  = cv2.imread(row['image_path'], cv2.IMREAD_GRAYSCALE)\n",
        "            msk  = cv2.imread(row['mask_path'],  cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None or msk is None:\n",
        "                continue\n",
        "\n",
        "            img = cv2.resize(img, self.img_size) / 255.0\n",
        "            msk = cv2.resize(msk, self.img_size) / 255.0\n",
        "\n",
        "            # add channel dimension\n",
        "            X.append(img.astype(np.float32)[...,None])\n",
        "            Y_seg.append(msk.astype(np.float32)[...,None])\n",
        "            Y_cls.append(row['label'])\n",
        "\n",
        "        X     = np.stack(X, axis=0)\n",
        "        Y_seg = np.stack(Y_seg, axis=0)\n",
        "        Y_cls = tf.keras.utils.to_categorical(Y_cls, num_classes=3).astype(np.float32)\n",
        "\n",
        "        return X, {'segmentation': Y_seg, 'classification': Y_cls}"
      ],
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        },
        "id": "TiRwpMWir4Td"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Generator with Albumentations ---\n",
        "class MultiTaskDataGenerator(Sequence):\n",
        "    def __init__(self, df, batch_size=8, img_size=(256,256), augment=False):\n",
        "        \"\"\"\n",
        "        df        : DataFrame with columns ['image_path','mask_path','label']\n",
        "        augment   : whether to apply on-the-fly augmentation\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size   = img_size\n",
        "        # define transform pipeline\n",
        "        if augment:\n",
        "            self.transform = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                A.OneOf([\n",
        "                    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
        "                    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n",
        "                    A.OpticalDistortion(distort_limit=0.3, p=0.3),\n",
        "                ], p=0.3),\n",
        "                A.Resize(img_size[0], img_size[1]),\n",
        "            ], additional_targets={'mask': 'mask'})\n",
        "        else:\n",
        "            self.transform = A.Compose([\n",
        "                A.Resize(img_size[0], img_size[1])\n",
        "            ], additional_targets={'mask': 'mask'})\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch = self.df.iloc[idx*self.batch_size : (idx+1)*self.batch_size]\n",
        "        X, Y_seg, Y_cls = [], [], []\n",
        "\n",
        "        for _, row in batch.iterrows():\n",
        "            img = cv2.imread(row['image_path'], cv2.IMREAD_GRAYSCALE)\n",
        "            msk = cv2.imread(row['mask_path'],  cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None or msk is None:\n",
        "                continue\n",
        "\n",
        "            # apply augmentation / resize\n",
        "            augmented = self.transform(image=img, mask=msk)\n",
        "            img, msk = augmented['image'], augmented['mask']\n",
        "\n",
        "            # normalize to [0,1]\n",
        "            img = img.astype(np.float32) / 255.0\n",
        "            msk = msk.astype(np.float32) / 255.0\n",
        "\n",
        "            # add channel dim\n",
        "            X.append(img[..., None])\n",
        "            Y_seg.append(msk[..., None])\n",
        "            Y_cls.append(row['label'])\n",
        "\n",
        "        X     = np.stack(X, axis=0)\n",
        "        Y_seg = np.stack(Y_seg, axis=0)\n",
        "        Y_cls = tf.keras.utils.to_categorical(Y_cls, num_classes=3).astype(np.float32)\n",
        "\n",
        "        return X, {'segmentation': Y_seg, 'classification': Y_cls}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:14:22.375575Z",
          "iopub.execute_input": "2025-08-01T19:14:22.375879Z",
          "iopub.status.idle": "2025-08-01T19:14:22.386955Z",
          "shell.execute_reply.started": "2025-08-01T19:14:22.375858Z",
          "shell.execute_reply": "2025-08-01T19:14:22.386238Z"
        },
        "id": "hDdJDjwUr4Td"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Dice Score and Loss ---\n",
        "def dice_score(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "class DiceLoss(tf.keras.losses.Loss):\n",
        "    def call(self, y_true, y_pred):\n",
        "        return 1.0 - dice_score(y_true, y_pred)\n",
        "\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def combined_dice_bce(y_true, y_pred):\n",
        "    return bce(y_true, y_pred) + DiceLoss()(y_true, y_pred)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:14:26.459715Z",
          "iopub.execute_input": "2025-08-01T19:14:26.460418Z",
          "iopub.status.idle": "2025-08-01T19:14:26.466852Z",
          "shell.execute_reply.started": "2025-08-01T19:14:26.460382Z",
          "shell.execute_reply": "2025-08-01T19:14:26.465874Z"
        },
        "id": "yL5o94Hbr4Td"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Definition (unchanged) ---\n",
        "def conv_block(x, filters, kernel_size=3, strides=1):\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(x, filters):\n",
        "    x = conv_block(x, filters)\n",
        "    x = conv_block(x, filters)\n",
        "    p = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(x, skip, filters):\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Concatenate()([x, skip])\n",
        "    x = conv_block(x, filters)\n",
        "    x = conv_block(x, filters)\n",
        "    return x\n",
        "\n",
        "def cbam_module(x, reduction_ratio=8):\n",
        "    channels = int(x.shape[-1])\n",
        "    avg_pool = layers.GlobalAveragePooling2D()(x)\n",
        "    max_pool = layers.GlobalMaxPooling2D()(x)\n",
        "    shared_dense_1 = layers.Dense(channels // reduction_ratio, activation='relu')\n",
        "    shared_dense_2 = layers.Dense(channels)\n",
        "    mlp_avg = shared_dense_2(shared_dense_1(avg_pool))\n",
        "    mlp_max = shared_dense_2(shared_dense_1(max_pool))\n",
        "    channel_attention = layers.Add()([mlp_avg, mlp_max])\n",
        "    channel_attention = layers.Activation('sigmoid')(channel_attention)\n",
        "    channel_attention = layers.Reshape((1, 1, channels))(channel_attention)\n",
        "    return layers.Multiply()([x, channel_attention])\n",
        "\n",
        "def build_encoder(inputs):\n",
        "    skips = []\n",
        "    x = inputs\n",
        "    for f in [32, 64, 128]:\n",
        "        s, x = encoder_block(x, f)\n",
        "        skips.append(s)\n",
        "    x = conv_block(x, 256)\n",
        "    return x, skips\n",
        "\n",
        "def build_segmentation_decoder(x, skips):\n",
        "    for i, f in reversed(list(enumerate([128, 64, 32]))):\n",
        "        x = decoder_block(x, skips[i], f)\n",
        "    x = layers.Conv2D(1, (1, 1), activation='sigmoid', name='segmentation')(x)\n",
        "    return x\n",
        "\n",
        "def build_classification_head(x, num_classes):\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax', name='classification')(x)\n",
        "    return x\n",
        "\n",
        "def build_braintumnet(input_shape=(256, 256, 1), num_classes=3):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x, skips = build_encoder(inputs)\n",
        "    x = cbam_module(x)\n",
        "    seg_output = build_segmentation_decoder(x, skips)\n",
        "    cls_output = build_classification_head(x, num_classes)\n",
        "    return Model(inputs=inputs, outputs=[seg_output, cls_output])"
      ],
      "metadata": {
        "_uuid": "575e63eb-3145-40df-8fbc-5520228b5410",
        "_cell_guid": "0789c6d9-07be-4dc6-ae76-917278b59dd7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:14:30.820399Z",
          "iopub.execute_input": "2025-08-01T19:14:30.820651Z",
          "iopub.status.idle": "2025-08-01T19:14:30.83047Z",
          "shell.execute_reply.started": "2025-08-01T19:14:30.820634Z",
          "shell.execute_reply": "2025-08-01T19:14:30.829721Z"
        },
        "id": "mPLQ57wJr4Te"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2: Load & split ===\n",
        "if __name__ == '__main__':\n",
        "    DATA_DIR = '/kaggle/input/figs-braintumor-segmentation-classification-sorted/restructured_dataset'\n",
        "    df = load_brisc_data(DATA_DIR, split='train')\n",
        "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "    train_gen = MultiTaskDataGenerator(train_df, batch_size=8, img_size=(256,256), augment = True)\n",
        "    val_gen   = MultiTaskDataGenerator(val_df,   batch_size=8, img_size=(256,256), augment = False)\n",
        "\n",
        "    model = build_braintumnet()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "        loss={'segmentation': combined_dice_bce, 'classification': 'categorical_crossentropy'},\n",
        "        loss_weights={'segmentation': 1.0, 'classification': 0.7},\n",
        "        metrics={'segmentation': dice_score,   'classification': 'accuracy'}\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:14:34.627788Z",
          "iopub.execute_input": "2025-08-01T19:14:34.628054Z",
          "iopub.status.idle": "2025-08-01T19:14:42.887815Z",
          "shell.execute_reply.started": "2025-08-01T19:14:34.628034Z",
          "shell.execute_reply": "2025-08-01T19:14:42.88727Z"
        },
        "id": "FfLwKVUnr4Te",
        "outputId": "36447bb5-2d9f-4cde-8388-a92ab7c896c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n/tmp/ipykernel_36/4243090114.py:18: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\nI0000 00:00:1754075681.458563      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2: define your two checkpoints ===\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# 1) Best-model checkpoint (only when val segmentation dice_score improves)\n",
        "checkpoint_best = ModelCheckpoint(\n",
        "    'braintumnet_best.h5',\n",
        "    monitor='val_segmentation_dice_score',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 2) “Last” checkpoint (overwrite every epoch)\n",
        "checkpoint_last = ModelCheckpoint(\n",
        "    'braintumnet_last.h5',\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_segmentation_dice_score',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [checkpoint_best, checkpoint_last, reduce_lr]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:15:33.423261Z",
          "iopub.execute_input": "2025-08-01T19:15:33.42354Z",
          "iopub.status.idle": "2025-08-01T19:15:33.428425Z",
          "shell.execute_reply.started": "2025-08-01T19:15:33.42352Z",
          "shell.execute_reply": "2025-08-01T19:15:33.427789Z"
        },
        "id": "6m6UBGVAr4Tf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: re-run training with callbacks ===\n",
        "\n",
        "# if you want to resume from a prior 'last' checkpoint, uncomment:\n",
        "# model = tf.   keras.models.load_model(\n",
        "#     'braintumnet_last.h5',\n",
        "#     custom_objects={'DiceLoss': DiceLoss, 'dice_score': dice_score}\n",
        "# )\n",
        "\n",
        "# Train (or resume) – here we train for 10 epochs total\n",
        "    # now fit exactly as before, with your callbacks…\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:15:42.136929Z",
          "iopub.execute_input": "2025-08-01T19:15:42.137222Z",
          "iopub.status.idle": "2025-08-01T19:43:59.050425Z",
          "shell.execute_reply.started": "2025-08-01T19:15:42.137201Z",
          "shell.execute_reply": "2025-08-01T19:43:59.049592Z"
        },
        "id": "zYKhFzDXr4Tf",
        "outputId": "e0330af2-74b5-4eb9-b388-2b11091927d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1/50\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1754075756.547713      94 service.cc:148] XLA service 0x7a05840027f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1754075756.548592      94 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1754075758.007497      94 cuda_dnn.cc:529] Loaded cuDNN version 90300\n2025-08-01 19:16:08.652976: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[128,96,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,96,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n2025-08-01 19:16:09.878546: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.225680354s\nTrying algorithm eng0{} for conv (f32[128,96,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,96,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\nI0000 00:00:1754075776.276190      94 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1: val_segmentation_dice_score improved from -inf to 0.02990, saving model to braintumnet_best.h5\n\nEpoch 1: saving model to braintumnet_last.h5\n253/253 - 87s - 343ms/step - classification_accuracy: 0.5830 - classification_loss: 0.9147 - loss: 1.7396 - segmentation_dice_score: 0.0824 - segmentation_loss: 1.0996 - val_classification_accuracy: 0.4515 - val_classification_loss: 1.6673 - val_loss: 2.2532 - val_segmentation_dice_score: 0.0299 - val_segmentation_loss: 1.1047 - learning_rate: 1.0000e-04\nEpoch 2/50\n\nEpoch 2: val_segmentation_dice_score improved from 0.02990 to 0.13851, saving model to braintumnet_best.h5\n\nEpoch 2: saving model to braintumnet_last.h5\n253/253 - 32s - 125ms/step - classification_accuracy: 0.6515 - classification_loss: 0.7910 - loss: 1.4176 - segmentation_dice_score: 0.2198 - segmentation_loss: 0.8637 - val_classification_accuracy: 0.4515 - val_classification_loss: 1.4046 - val_loss: 1.9369 - val_segmentation_dice_score: 0.1385 - val_segmentation_loss: 0.9649 - learning_rate: 1.0000e-04\nEpoch 3/50\n\nEpoch 3: val_segmentation_dice_score improved from 0.13851 to 0.25971, saving model to braintumnet_best.h5\n\nEpoch 3: saving model to braintumnet_last.h5\n253/253 - 34s - 136ms/step - classification_accuracy: 0.6991 - classification_loss: 0.7241 - loss: 1.2191 - segmentation_dice_score: 0.3553 - segmentation_loss: 0.7121 - val_classification_accuracy: 0.5129 - val_classification_loss: 0.9650 - val_loss: 1.6174 - val_segmentation_dice_score: 0.2597 - val_segmentation_loss: 0.9280 - learning_rate: 1.0000e-04\nEpoch 4/50\n\nEpoch 4: val_segmentation_dice_score improved from 0.25971 to 0.52642, saving model to braintumnet_best.h5\n\nEpoch 4: saving model to braintumnet_last.h5\n253/253 - 33s - 132ms/step - classification_accuracy: 0.7442 - classification_loss: 0.6243 - loss: 1.0668 - segmentation_dice_score: 0.4325 - segmentation_loss: 0.6304 - val_classification_accuracy: 0.8099 - val_classification_loss: 0.4713 - val_loss: 0.8684 - val_segmentation_dice_score: 0.5264 - val_segmentation_loss: 0.5310 - learning_rate: 1.0000e-04\nEpoch 5/50\n\nEpoch 5: val_segmentation_dice_score improved from 0.52642 to 0.52771, saving model to braintumnet_best.h5\n\nEpoch 5: saving model to braintumnet_last.h5\n253/253 - 34s - 133ms/step - classification_accuracy: 0.7977 - classification_loss: 0.5190 - loss: 0.9173 - segmentation_dice_score: 0.5031 - segmentation_loss: 0.5556 - val_classification_accuracy: 0.7525 - val_classification_loss: 0.5890 - val_loss: 0.9522 - val_segmentation_dice_score: 0.5277 - val_segmentation_loss: 0.5294 - learning_rate: 1.0000e-04\nEpoch 6/50\n\nEpoch 6: val_segmentation_dice_score improved from 0.52771 to 0.58981, saving model to braintumnet_best.h5\n\nEpoch 6: saving model to braintumnet_last.h5\n\nEpoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n253/253 - 34s - 136ms/step - classification_accuracy: 0.8275 - classification_loss: 0.4474 - loss: 0.8339 - segmentation_dice_score: 0.5354 - segmentation_loss: 0.5218 - val_classification_accuracy: 0.8614 - val_classification_loss: 0.3537 - val_loss: 0.7145 - val_segmentation_dice_score: 0.5898 - val_segmentation_loss: 0.4612 - learning_rate: 1.0000e-04\nEpoch 7/50\n\nEpoch 7: val_segmentation_dice_score improved from 0.58981 to 0.62407, saving model to braintumnet_best.h5\n\nEpoch 7: saving model to braintumnet_last.h5\n253/253 - 33s - 130ms/step - classification_accuracy: 0.8800 - classification_loss: 0.3507 - loss: 0.6961 - segmentation_dice_score: 0.6000 - segmentation_loss: 0.4503 - val_classification_accuracy: 0.9050 - val_classification_loss: 0.2749 - val_loss: 0.6183 - val_segmentation_dice_score: 0.6241 - val_segmentation_loss: 0.4222 - learning_rate: 5.0000e-05\nEpoch 8/50\n\nEpoch 8: val_segmentation_dice_score improved from 0.62407 to 0.64701, saving model to braintumnet_best.h5\n\nEpoch 8: saving model to braintumnet_last.h5\n253/253 - 33s - 130ms/step - classification_accuracy: 0.8716 - classification_loss: 0.3434 - loss: 0.6741 - segmentation_dice_score: 0.6166 - segmentation_loss: 0.4327 - val_classification_accuracy: 0.8970 - val_classification_loss: 0.2724 - val_loss: 0.5950 - val_segmentation_dice_score: 0.6470 - val_segmentation_loss: 0.4004 - learning_rate: 5.0000e-05\nEpoch 9/50\n\nEpoch 9: val_segmentation_dice_score improved from 0.64701 to 0.67057, saving model to braintumnet_best.h5\n\nEpoch 9: saving model to braintumnet_last.h5\n253/253 - 34s - 135ms/step - classification_accuracy: 0.8954 - classification_loss: 0.3104 - loss: 0.6364 - segmentation_dice_score: 0.6300 - segmentation_loss: 0.4189 - val_classification_accuracy: 0.9208 - val_classification_loss: 0.2079 - val_loss: 0.5221 - val_segmentation_dice_score: 0.6706 - val_segmentation_loss: 0.3736 - learning_rate: 5.0000e-05\nEpoch 10/50\n\nEpoch 10: val_segmentation_dice_score did not improve from 0.67057\n\nEpoch 10: saving model to braintumnet_last.h5\n253/253 - 31s - 123ms/step - classification_accuracy: 0.9088 - classification_loss: 0.2732 - loss: 0.5900 - segmentation_dice_score: 0.6476 - segmentation_loss: 0.3988 - val_classification_accuracy: 0.8931 - val_classification_loss: 0.2688 - val_loss: 0.5888 - val_segmentation_dice_score: 0.6485 - val_segmentation_loss: 0.3974 - learning_rate: 5.0000e-05\nEpoch 11/50\n\nEpoch 11: val_segmentation_dice_score improved from 0.67057 to 0.67286, saving model to braintumnet_best.h5\n\nEpoch 11: saving model to braintumnet_last.h5\n\nEpoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n253/253 - 32s - 126ms/step - classification_accuracy: 0.9068 - classification_loss: 0.2775 - loss: 0.5855 - segmentation_dice_score: 0.6546 - segmentation_loss: 0.3921 - val_classification_accuracy: 0.9248 - val_classification_loss: 0.1969 - val_loss: 0.5148 - val_segmentation_dice_score: 0.6729 - val_segmentation_loss: 0.3721 - learning_rate: 5.0000e-05\nEpoch 12/50\n\nEpoch 12: val_segmentation_dice_score improved from 0.67286 to 0.68324, saving model to braintumnet_best.h5\n\nEpoch 12: saving model to braintumnet_last.h5\n253/253 - 34s - 135ms/step - classification_accuracy: 0.9147 - classification_loss: 0.2449 - loss: 0.5401 - segmentation_dice_score: 0.6745 - segmentation_loss: 0.3691 - val_classification_accuracy: 0.9307 - val_classification_loss: 0.1876 - val_loss: 0.4947 - val_segmentation_dice_score: 0.6832 - val_segmentation_loss: 0.3590 - learning_rate: 2.5000e-05\nEpoch 13/50\n\nEpoch 13: val_segmentation_dice_score improved from 0.68324 to 0.69322, saving model to braintumnet_best.h5\n\nEpoch 13: saving model to braintumnet_last.h5\n253/253 - 32s - 128ms/step - classification_accuracy: 0.9187 - classification_loss: 0.2308 - loss: 0.5219 - segmentation_dice_score: 0.6836 - segmentation_loss: 0.3596 - val_classification_accuracy: 0.9267 - val_classification_loss: 0.1906 - val_loss: 0.4850 - val_segmentation_dice_score: 0.6932 - val_segmentation_loss: 0.3472 - learning_rate: 2.5000e-05\nEpoch 14/50\n\nEpoch 14: val_segmentation_dice_score did not improve from 0.69322\n\nEpoch 14: saving model to braintumnet_last.h5\n253/253 - 33s - 131ms/step - classification_accuracy: 0.9281 - classification_loss: 0.2267 - loss: 0.5149 - segmentation_dice_score: 0.6875 - segmentation_loss: 0.3555 - val_classification_accuracy: 0.9347 - val_classification_loss: 0.1845 - val_loss: 0.4904 - val_segmentation_dice_score: 0.6856 - val_segmentation_loss: 0.3574 - learning_rate: 2.5000e-05\nEpoch 15/50\n\nEpoch 15: val_segmentation_dice_score improved from 0.69322 to 0.69570, saving model to braintumnet_best.h5\n\nEpoch 15: saving model to braintumnet_last.h5\n253/253 - 33s - 130ms/step - classification_accuracy: 0.9192 - classification_loss: 0.2175 - loss: 0.5104 - segmentation_dice_score: 0.6838 - segmentation_loss: 0.3598 - val_classification_accuracy: 0.9366 - val_classification_loss: 0.1651 - val_loss: 0.4642 - val_segmentation_dice_score: 0.6957 - val_segmentation_loss: 0.3450 - learning_rate: 2.5000e-05\nEpoch 16/50\n\nEpoch 16: val_segmentation_dice_score improved from 0.69570 to 0.69970, saving model to braintumnet_best.h5\n\nEpoch 16: saving model to braintumnet_last.h5\n\nEpoch 16: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9306 - classification_loss: 0.2079 - loss: 0.4914 - segmentation_dice_score: 0.6965 - segmentation_loss: 0.3455 - val_classification_accuracy: 0.9307 - val_classification_loss: 0.1899 - val_loss: 0.4779 - val_segmentation_dice_score: 0.6997 - val_segmentation_loss: 0.3402 - learning_rate: 2.5000e-05\nEpoch 17/50\n\nEpoch 17: val_segmentation_dice_score improved from 0.69970 to 0.70627, saving model to braintumnet_best.h5\n\nEpoch 17: saving model to braintumnet_last.h5\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9470 - classification_loss: 0.1843 - loss: 0.4714 - segmentation_dice_score: 0.6995 - segmentation_loss: 0.3417 - val_classification_accuracy: 0.9406 - val_classification_loss: 0.1630 - val_loss: 0.4529 - val_segmentation_dice_score: 0.7063 - val_segmentation_loss: 0.3342 - learning_rate: 1.2500e-05\nEpoch 18/50\n\nEpoch 18: val_segmentation_dice_score did not improve from 0.70627\n\nEpoch 18: saving model to braintumnet_last.h5\n253/253 - 31s - 124ms/step - classification_accuracy: 0.9351 - classification_loss: 0.1926 - loss: 0.4702 - segmentation_dice_score: 0.7061 - segmentation_loss: 0.3347 - val_classification_accuracy: 0.9347 - val_classification_loss: 0.1815 - val_loss: 0.4672 - val_segmentation_dice_score: 0.7048 - val_segmentation_loss: 0.3352 - learning_rate: 1.2500e-05\nEpoch 19/50\n\nEpoch 19: val_segmentation_dice_score improved from 0.70627 to 0.71164, saving model to braintumnet_best.h5\n\nEpoch 19: saving model to braintumnet_last.h5\n253/253 - 32s - 127ms/step - classification_accuracy: 0.9395 - classification_loss: 0.1876 - loss: 0.4628 - segmentation_dice_score: 0.7094 - segmentation_loss: 0.3308 - val_classification_accuracy: 0.9446 - val_classification_loss: 0.1576 - val_loss: 0.4433 - val_segmentation_dice_score: 0.7116 - val_segmentation_loss: 0.3287 - learning_rate: 1.2500e-05\nEpoch 20/50\n\nEpoch 20: val_segmentation_dice_score improved from 0.71164 to 0.71602, saving model to braintumnet_best.h5\n\nEpoch 20: saving model to braintumnet_last.h5\n253/253 - 33s - 132ms/step - classification_accuracy: 0.9346 - classification_loss: 0.1868 - loss: 0.4561 - segmentation_dice_score: 0.7155 - segmentation_loss: 0.3247 - val_classification_accuracy: 0.9426 - val_classification_loss: 0.1593 - val_loss: 0.4379 - val_segmentation_dice_score: 0.7160 - val_segmentation_loss: 0.3232 - learning_rate: 1.2500e-05\nEpoch 21/50\n\nEpoch 21: val_segmentation_dice_score did not improve from 0.71602\n\nEpoch 21: saving model to braintumnet_last.h5\n\nEpoch 21: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n253/253 - 34s - 135ms/step - classification_accuracy: 0.9484 - classification_loss: 0.1709 - loss: 0.4419 - segmentation_dice_score: 0.7176 - segmentation_loss: 0.3221 - val_classification_accuracy: 0.9485 - val_classification_loss: 0.1528 - val_loss: 0.4353 - val_segmentation_dice_score: 0.7145 - val_segmentation_loss: 0.3244 - learning_rate: 1.2500e-05\nEpoch 22/50\n\nEpoch 22: val_segmentation_dice_score improved from 0.71602 to 0.71788, saving model to braintumnet_best.h5\n\nEpoch 22: saving model to braintumnet_last.h5\n253/253 - 32s - 128ms/step - classification_accuracy: 0.9460 - classification_loss: 0.1688 - loss: 0.4405 - segmentation_dice_score: 0.7179 - segmentation_loss: 0.3217 - val_classification_accuracy: 0.9465 - val_classification_loss: 0.1606 - val_loss: 0.4385 - val_segmentation_dice_score: 0.7179 - val_segmentation_loss: 0.3214 - learning_rate: 6.2500e-06\nEpoch 23/50\n\nEpoch 23: val_segmentation_dice_score improved from 0.71788 to 0.72033, saving model to braintumnet_best.h5\n\nEpoch 23: saving model to braintumnet_last.h5\n253/253 - 34s - 133ms/step - classification_accuracy: 0.9494 - classification_loss: 0.1731 - loss: 0.4415 - segmentation_dice_score: 0.7192 - segmentation_loss: 0.3203 - val_classification_accuracy: 0.9446 - val_classification_loss: 0.1461 - val_loss: 0.4246 - val_segmentation_dice_score: 0.7203 - val_segmentation_loss: 0.3186 - learning_rate: 6.2500e-06\nEpoch 24/50\n\nEpoch 24: val_segmentation_dice_score did not improve from 0.72033\n\nEpoch 24: saving model to braintumnet_last.h5\n253/253 - 32s - 125ms/step - classification_accuracy: 0.9484 - classification_loss: 0.1665 - loss: 0.4331 - segmentation_dice_score: 0.7229 - segmentation_loss: 0.3159 - val_classification_accuracy: 0.9446 - val_classification_loss: 0.1522 - val_loss: 0.4291 - val_segmentation_dice_score: 0.7198 - val_segmentation_loss: 0.3194 - learning_rate: 6.2500e-06\nEpoch 25/50\n\nEpoch 25: val_segmentation_dice_score did not improve from 0.72033\n\nEpoch 25: saving model to braintumnet_last.h5\n253/253 - 32s - 128ms/step - classification_accuracy: 0.9519 - classification_loss: 0.1589 - loss: 0.4253 - segmentation_dice_score: 0.7253 - segmentation_loss: 0.3135 - val_classification_accuracy: 0.9505 - val_classification_loss: 0.1480 - val_loss: 0.4376 - val_segmentation_dice_score: 0.7110 - val_segmentation_loss: 0.3297 - learning_rate: 6.2500e-06\nEpoch 26/50\n\nEpoch 26: val_segmentation_dice_score improved from 0.72033 to 0.72317, saving model to braintumnet_best.h5\n\nEpoch 26: saving model to braintumnet_last.h5\n\nEpoch 26: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n253/253 - 34s - 134ms/step - classification_accuracy: 0.9504 - classification_loss: 0.1678 - loss: 0.4334 - segmentation_dice_score: 0.7239 - segmentation_loss: 0.3153 - val_classification_accuracy: 0.9406 - val_classification_loss: 0.1460 - val_loss: 0.4221 - val_segmentation_dice_score: 0.7232 - val_segmentation_loss: 0.3161 - learning_rate: 6.2500e-06\nEpoch 27/50\n\nEpoch 27: val_segmentation_dice_score improved from 0.72317 to 0.72453, saving model to braintumnet_best.h5\n\nEpoch 27: saving model to braintumnet_last.h5\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9524 - classification_loss: 0.1577 - loss: 0.4210 - segmentation_dice_score: 0.7280 - segmentation_loss: 0.3104 - val_classification_accuracy: 0.9465 - val_classification_loss: 0.1470 - val_loss: 0.4212 - val_segmentation_dice_score: 0.7245 - val_segmentation_loss: 0.3142 - learning_rate: 3.1250e-06\nEpoch 28/50\n\nEpoch 28: val_segmentation_dice_score did not improve from 0.72453\n\nEpoch 28: saving model to braintumnet_last.h5\n253/253 - 31s - 124ms/step - classification_accuracy: 0.9529 - classification_loss: 0.1592 - loss: 0.4204 - segmentation_dice_score: 0.7305 - segmentation_loss: 0.3082 - val_classification_accuracy: 0.9485 - val_classification_loss: 0.1462 - val_loss: 0.4224 - val_segmentation_dice_score: 0.7227 - val_segmentation_loss: 0.3159 - learning_rate: 3.1250e-06\nEpoch 29/50\n\nEpoch 29: val_segmentation_dice_score improved from 0.72453 to 0.72459, saving model to braintumnet_best.h5\n\nEpoch 29: saving model to braintumnet_last.h5\n253/253 - 32s - 127ms/step - classification_accuracy: 0.9524 - classification_loss: 0.1534 - loss: 0.4152 - segmentation_dice_score: 0.7307 - segmentation_loss: 0.3072 - val_classification_accuracy: 0.9505 - val_classification_loss: 0.1455 - val_loss: 0.4202 - val_segmentation_dice_score: 0.7246 - val_segmentation_loss: 0.3141 - learning_rate: 3.1250e-06\nEpoch 30/50\n\nEpoch 30: val_segmentation_dice_score did not improve from 0.72459\n\nEpoch 30: saving model to braintumnet_last.h5\n253/253 - 32s - 128ms/step - classification_accuracy: 0.9479 - classification_loss: 0.1609 - loss: 0.4281 - segmentation_dice_score: 0.7249 - segmentation_loss: 0.3146 - val_classification_accuracy: 0.9525 - val_classification_loss: 0.1479 - val_loss: 0.4232 - val_segmentation_dice_score: 0.7238 - val_segmentation_loss: 0.3153 - learning_rate: 3.1250e-06\nEpoch 31/50\n\nEpoch 31: val_segmentation_dice_score improved from 0.72459 to 0.72508, saving model to braintumnet_best.h5\n\nEpoch 31: saving model to braintumnet_last.h5\n\nEpoch 31: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9430 - classification_loss: 0.1579 - loss: 0.4228 - segmentation_dice_score: 0.7269 - segmentation_loss: 0.3121 - val_classification_accuracy: 0.9505 - val_classification_loss: 0.1451 - val_loss: 0.4191 - val_segmentation_dice_score: 0.7251 - val_segmentation_loss: 0.3133 - learning_rate: 3.1250e-06\nEpoch 32/50\n\nEpoch 32: val_segmentation_dice_score did not improve from 0.72508\n\nEpoch 32: saving model to braintumnet_last.h5\n253/253 - 31s - 123ms/step - classification_accuracy: 0.9465 - classification_loss: 0.1620 - loss: 0.4177 - segmentation_dice_score: 0.7340 - segmentation_loss: 0.3036 - val_classification_accuracy: 0.9485 - val_classification_loss: 0.1429 - val_loss: 0.4192 - val_segmentation_dice_score: 0.7235 - val_segmentation_loss: 0.3151 - learning_rate: 1.5625e-06\nEpoch 33/50\n\nEpoch 33: val_segmentation_dice_score improved from 0.72508 to 0.72540, saving model to braintumnet_best.h5\n\nEpoch 33: saving model to braintumnet_last.h5\n253/253 - 33s - 132ms/step - classification_accuracy: 0.9569 - classification_loss: 0.1535 - loss: 0.4168 - segmentation_dice_score: 0.7296 - segmentation_loss: 0.3090 - val_classification_accuracy: 0.9525 - val_classification_loss: 0.1428 - val_loss: 0.4172 - val_segmentation_dice_score: 0.7254 - val_segmentation_loss: 0.3132 - learning_rate: 1.5625e-06\nEpoch 34/50\n\nEpoch 34: val_segmentation_dice_score did not improve from 0.72540\n\nEpoch 34: saving model to braintumnet_last.h5\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9514 - classification_loss: 0.1551 - loss: 0.4149 - segmentation_dice_score: 0.7300 - segmentation_loss: 0.3089 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1441 - val_loss: 0.4193 - val_segmentation_dice_score: 0.7246 - val_segmentation_loss: 0.3142 - learning_rate: 1.5625e-06\nEpoch 35/50\n\nEpoch 35: val_segmentation_dice_score did not improve from 0.72540\n\nEpoch 35: saving model to braintumnet_last.h5\n253/253 - 32s - 126ms/step - classification_accuracy: 0.9494 - classification_loss: 0.1540 - loss: 0.4108 - segmentation_dice_score: 0.7351 - segmentation_loss: 0.3024 - val_classification_accuracy: 0.9525 - val_classification_loss: 0.1451 - val_loss: 0.4192 - val_segmentation_dice_score: 0.7252 - val_segmentation_loss: 0.3134 - learning_rate: 1.5625e-06\nEpoch 36/50\n\nEpoch 36: val_segmentation_dice_score did not improve from 0.72540\n\nEpoch 36: saving model to braintumnet_last.h5\n\nEpoch 36: ReduceLROnPlateau reducing learning rate to 1e-06.\n253/253 - 33s - 130ms/step - classification_accuracy: 0.9504 - classification_loss: 0.1549 - loss: 0.4115 - segmentation_dice_score: 0.7352 - segmentation_loss: 0.3024 - val_classification_accuracy: 0.9505 - val_classification_loss: 0.1434 - val_loss: 0.4183 - val_segmentation_dice_score: 0.7251 - val_segmentation_loss: 0.3139 - learning_rate: 1.5625e-06\nEpoch 37/50\n\nEpoch 37: val_segmentation_dice_score improved from 0.72540 to 0.72638, saving model to braintumnet_best.h5\n\nEpoch 37: saving model to braintumnet_last.h5\n253/253 - 33s - 130ms/step - classification_accuracy: 0.9470 - classification_loss: 0.1525 - loss: 0.4099 - segmentation_dice_score: 0.7351 - segmentation_loss: 0.3025 - val_classification_accuracy: 0.9485 - val_classification_loss: 0.1433 - val_loss: 0.4166 - val_segmentation_dice_score: 0.7264 - val_segmentation_loss: 0.3123 - learning_rate: 1.0000e-06\nEpoch 38/50\n\nEpoch 38: val_segmentation_dice_score did not improve from 0.72638\n\nEpoch 38: saving model to braintumnet_last.h5\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9514 - classification_loss: 0.1523 - loss: 0.4121 - segmentation_dice_score: 0.7332 - segmentation_loss: 0.3052 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1443 - val_loss: 0.4205 - val_segmentation_dice_score: 0.7239 - val_segmentation_loss: 0.3152 - learning_rate: 1.0000e-06\nEpoch 39/50\n\nEpoch 39: val_segmentation_dice_score did not improve from 0.72638\n\nEpoch 39: saving model to braintumnet_last.h5\n253/253 - 32s - 128ms/step - classification_accuracy: 0.9484 - classification_loss: 0.1516 - loss: 0.4147 - segmentation_dice_score: 0.7308 - segmentation_loss: 0.3078 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1435 - val_loss: 0.4172 - val_segmentation_dice_score: 0.7263 - val_segmentation_loss: 0.3125 - learning_rate: 1.0000e-06\nEpoch 40/50\n\nEpoch 40: val_segmentation_dice_score improved from 0.72638 to 0.72644, saving model to braintumnet_best.h5\n\nEpoch 40: saving model to braintumnet_last.h5\n253/253 - 34s - 136ms/step - classification_accuracy: 0.9524 - classification_loss: 0.1570 - loss: 0.4155 - segmentation_dice_score: 0.7333 - segmentation_loss: 0.3049 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1428 - val_loss: 0.4164 - val_segmentation_dice_score: 0.7264 - val_segmentation_loss: 0.3124 - learning_rate: 1.0000e-06\nEpoch 41/50\n\nEpoch 41: val_segmentation_dice_score did not improve from 0.72644\n\nEpoch 41: saving model to braintumnet_last.h5\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9549 - classification_loss: 0.1493 - loss: 0.4072 - segmentation_dice_score: 0.7353 - segmentation_loss: 0.3024 - val_classification_accuracy: 0.9525 - val_classification_loss: 0.1439 - val_loss: 0.4185 - val_segmentation_dice_score: 0.7253 - val_segmentation_loss: 0.3135 - learning_rate: 1.0000e-06\nEpoch 42/50\n\nEpoch 42: val_segmentation_dice_score improved from 0.72644 to 0.72648, saving model to braintumnet_best.h5\n\nEpoch 42: saving model to braintumnet_last.h5\n253/253 - 35s - 136ms/step - classification_accuracy: 0.9470 - classification_loss: 0.1599 - loss: 0.4162 - segmentation_dice_score: 0.7342 - segmentation_loss: 0.3035 - val_classification_accuracy: 0.9525 - val_classification_loss: 0.1432 - val_loss: 0.4166 - val_segmentation_dice_score: 0.7265 - val_segmentation_loss: 0.3122 - learning_rate: 1.0000e-06\nEpoch 43/50\n\nEpoch 43: val_segmentation_dice_score improved from 0.72648 to 0.72669, saving model to braintumnet_best.h5\n\nEpoch 43: saving model to braintumnet_last.h5\n253/253 - 32s - 126ms/step - classification_accuracy: 0.9504 - classification_loss: 0.1544 - loss: 0.4105 - segmentation_dice_score: 0.7359 - segmentation_loss: 0.3017 - val_classification_accuracy: 0.9525 - val_classification_loss: 0.1426 - val_loss: 0.4158 - val_segmentation_dice_score: 0.7267 - val_segmentation_loss: 0.3119 - learning_rate: 1.0000e-06\nEpoch 44/50\n\nEpoch 44: val_segmentation_dice_score improved from 0.72669 to 0.72681, saving model to braintumnet_best.h5\n\nEpoch 44: saving model to braintumnet_last.h5\n253/253 - 33s - 131ms/step - classification_accuracy: 0.9484 - classification_loss: 0.1535 - loss: 0.4098 - segmentation_dice_score: 0.7359 - segmentation_loss: 0.3016 - val_classification_accuracy: 0.9525 - val_classification_loss: 0.1431 - val_loss: 0.4161 - val_segmentation_dice_score: 0.7268 - val_segmentation_loss: 0.3117 - learning_rate: 1.0000e-06\nEpoch 45/50\n\nEpoch 45: val_segmentation_dice_score improved from 0.72681 to 0.72758, saving model to braintumnet_best.h5\n\nEpoch 45: saving model to braintumnet_last.h5\n253/253 - 34s - 136ms/step - classification_accuracy: 0.9588 - classification_loss: 0.1512 - loss: 0.4108 - segmentation_dice_score: 0.7338 - segmentation_loss: 0.3043 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1429 - val_loss: 0.4153 - val_segmentation_dice_score: 0.7276 - val_segmentation_loss: 0.3111 - learning_rate: 1.0000e-06\nEpoch 46/50\n\nEpoch 46: val_segmentation_dice_score did not improve from 0.72758\n\nEpoch 46: saving model to braintumnet_last.h5\n253/253 - 34s - 134ms/step - classification_accuracy: 0.9574 - classification_loss: 0.1461 - loss: 0.4053 - segmentation_dice_score: 0.7358 - segmentation_loss: 0.3023 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1427 - val_loss: 0.4161 - val_segmentation_dice_score: 0.7268 - val_segmentation_loss: 0.3120 - learning_rate: 1.0000e-06\nEpoch 47/50\n\nEpoch 47: val_segmentation_dice_score did not improve from 0.72758\n\nEpoch 47: saving model to braintumnet_last.h5\n253/253 - 32s - 125ms/step - classification_accuracy: 0.9593 - classification_loss: 0.1432 - loss: 0.4049 - segmentation_dice_score: 0.7342 - segmentation_loss: 0.3038 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1426 - val_loss: 0.4173 - val_segmentation_dice_score: 0.7256 - val_segmentation_loss: 0.3132 - learning_rate: 1.0000e-06\nEpoch 48/50\n\nEpoch 48: val_segmentation_dice_score did not improve from 0.72758\n\nEpoch 48: saving model to braintumnet_last.h5\n253/253 - 34s - 134ms/step - classification_accuracy: 0.9539 - classification_loss: 0.1464 - loss: 0.4075 - segmentation_dice_score: 0.7333 - segmentation_loss: 0.3045 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1421 - val_loss: 0.4147 - val_segmentation_dice_score: 0.7275 - val_segmentation_loss: 0.3111 - learning_rate: 1.0000e-06\nEpoch 49/50\n\nEpoch 49: val_segmentation_dice_score improved from 0.72758 to 0.72812, saving model to braintumnet_best.h5\n\nEpoch 49: saving model to braintumnet_last.h5\n253/253 - 33s - 129ms/step - classification_accuracy: 0.9489 - classification_loss: 0.1530 - loss: 0.4167 - segmentation_dice_score: 0.7299 - segmentation_loss: 0.3090 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1424 - val_loss: 0.4142 - val_segmentation_dice_score: 0.7281 - val_segmentation_loss: 0.3103 - learning_rate: 1.0000e-06\nEpoch 50/50\n\nEpoch 50: val_segmentation_dice_score did not improve from 0.72812\n\nEpoch 50: saving model to braintumnet_last.h5\n253/253 - 33s - 130ms/step - classification_accuracy: 0.9509 - classification_loss: 0.1611 - loss: 0.4172 - segmentation_dice_score: 0.7336 - segmentation_loss: 0.3047 - val_classification_accuracy: 0.9545 - val_classification_loss: 0.1416 - val_loss: 0.4138 - val_segmentation_dice_score: 0.7280 - val_segmentation_loss: 0.3106 - learning_rate: 1.0000e-06\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "****to resume later****"
      ],
      "metadata": {
        "id": "SRLoH32Gr4Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to resume later\n",
        "\n",
        "\n",
        "# rebuild & compile\n",
        "model = build_braintumnet()\n",
        "model.compile(...)\n",
        "\n",
        "# load last checkpoint\n",
        "model = tf.keras.models.load_model(\n",
        "    'braintumnet_last.h5',\n",
        "    custom_objects={'DiceLoss': DiceLoss, 'dice_score': dice_score}\n",
        ")\n",
        "\n",
        "# continue training up to, say, 20 epochs total\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=20,\n",
        "    initial_epoch=10,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "lW2KwJNzr4Tg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tf.keras.models.load_model(\n",
        "    'braintumnet_best.h5',\n",
        "    custom_objects={'DiceLoss': DiceLoss, 'dice_score': dice_score}\n",
        ")\n",
        "# then do: preds_seg, preds_cls = best_model.predict(my_test_images)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "PLJOFqIXr4Tg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Your TEST-set dirs\n",
        "test_img_dir  = '/kaggle/input/figs-braintumor-segmentation-classification-sorted/restructured_dataset/segmentation_task/test/images'\n",
        "test_mask_dir = '/kaggle/input/figs-braintumor-segmentation-classification-sorted/restructured_dataset/segmentation_task/test/masks'\n",
        "test_cls_dir  = '/kaggle/input/figs-braintumor-segmentation-classification-sorted/restructured_dataset/classification_task/test'\n",
        "\n",
        "# 2) Build the test DataFrame\n",
        "class_map = {'glioma':0, 'meningioma':1, 'pituitary':2}\n",
        "records = []\n",
        "\n",
        "for cls_name, cls_idx in class_map.items():\n",
        "    cls_folder = os.path.join(test_cls_dir, cls_name)\n",
        "    if not os.path.isdir(cls_folder):\n",
        "        continue\n",
        "\n",
        "    for fname in os.listdir(cls_folder):\n",
        "        if not fname.lower().endswith('.jpg'):\n",
        "            continue\n",
        "\n",
        "        # fname is e.g. \"2948.jpg\"\n",
        "        base, _   = os.path.splitext(fname)\n",
        "        seg_fname = f\"{cls_name}_{base}.jpg\"    # e.g. \"glioma_2948.jpg\"\n",
        "        mask_fname= f\"{cls_name}_{base}.png\"\n",
        "\n",
        "        img_path  = os.path.join(test_img_dir, seg_fname)\n",
        "        mask_path = os.path.join(test_mask_dir, mask_fname)\n",
        "\n",
        "        # only keep if both exist\n",
        "        if not (os.path.exists(img_path) and os.path.exists(mask_path)):\n",
        "            print(f\"[!] skipping missing pair: {seg_fname} / {mask_fname}\")\n",
        "            continue\n",
        "\n",
        "        # we’ll feed the generator seg_fname + label\n",
        "        records.append({\n",
        "            'filename': seg_fname,\n",
        "            'label':    cls_idx\n",
        "        })\n",
        "\n",
        "test_df = pd.DataFrame(records).reset_index(drop=True)\n",
        "print(f\"Found {len(test_df)} test samples.\")\n",
        "\n",
        "# 3) Instantiate the TEST generator exactly as before\n",
        "test_gen = MultiTaskDataGenerator(\n",
        "    test_df,\n",
        "    image_dir=test_img_dir,\n",
        "    mask_dir=test_mask_dir,\n",
        "    batch_size=8\n",
        ")\n",
        "\n",
        "# quick sanity\n",
        "print(\"Generator length (batches):\", len(test_gen))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-28T19:36:18.095104Z",
          "iopub.execute_input": "2025-07-28T19:36:18.095408Z",
          "iopub.status.idle": "2025-07-28T19:36:21.993961Z",
          "shell.execute_reply.started": "2025-07-28T19:36:18.095386Z",
          "shell.execute_reply": "2025-07-28T19:36:21.993031Z"
        },
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": true
        },
        "collapsed": true,
        "id": "6cDyec47r4Tg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Load test DataFrame\n",
        "test_df = load_brisc_data(DATA_DIR, split='test')\n",
        "# If you have test_df:\n",
        "test_gen = MultiTaskDataGenerator(test_df, batch_size=8, img_size=(256,256), augment = False)\n",
        "print(f\"Test samples: {len(test_df)}\")\n",
        "\n",
        "# 2) Build arrays\n",
        "X         = []\n",
        "Y_seg_true= []\n",
        "y_cls_true= []\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "    # grayscale read\n",
        "    img  = cv2.imread(row['image_path'], cv2.IMREAD_GRAYSCALE)\n",
        "    msk  = cv2.imread(row['mask_path'],  cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None or msk is None:\n",
        "        continue\n",
        "\n",
        "    # resize & normalize\n",
        "    img = cv2.resize(img, (256,256)) / 255.0\n",
        "    msk = cv2.resize(msk, (256,256)) / 255.0\n",
        "\n",
        "    # add channel dim\n",
        "    X.append(img.astype(np.float32)[...,None])\n",
        "    Y_seg_true.append(msk.astype(np.float32)[...,None])\n",
        "    y_cls_true.append(row['label'])\n",
        "\n",
        "X          = np.stack(X, axis=0)\n",
        "Y_seg_true = np.stack(Y_seg_true, axis=0)\n",
        "y_cls_true = np.array(y_cls_true, dtype=int)\n",
        "\n",
        "print(f\"  → Loaded X: {X.shape}, Y_seg: {Y_seg_true.shape}, y_cls: {y_cls_true.shape}\")\n",
        "\n",
        "# 3) Load your best model\n",
        "best_model = tf.keras.models.load_model(\n",
        "    'braintumnet_best.h5',\n",
        "    custom_objects={'DiceLoss': DiceLoss, 'dice_score': dice_score}\n",
        ")\n",
        "\n",
        "# 4) Predict once\n",
        "preds_seg, preds_cls = best_model.predict(X, verbose=1)\n",
        "\n",
        "# ── Segmentation metrics ─────────────────────────────────────────────────────\n",
        "# binarize & compute per‐image Dice\n",
        "dice_scores = []\n",
        "for true, pred in zip(Y_seg_true, preds_seg):\n",
        "    p_bin = (pred > 0.5).astype(np.float32)\n",
        "    inter = np.sum(true * p_bin)\n",
        "    d = (2*inter + 1e-6) / (np.sum(true) + np.sum(p_bin) + 1e-6)\n",
        "    dice_scores.append(d)\n",
        "\n",
        "print(f\"\\nSegmentation Mean Dice on test set: {np.mean(dice_scores):.4f}\")\n",
        "\n",
        "# ── Classification metrics ────────────────────────────────────────────────────\n",
        "y_pred = np.argmax(preds_cls, axis=1)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(\n",
        "    y_cls_true,\n",
        "    y_pred,\n",
        "    labels=[0,1,2],\n",
        "    target_names=['glioma','meningioma','pituitary']\n",
        "))\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_cls_true, y_pred, labels=[0,1,2]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "n6Bb2dXur4Tg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#code for inference on a few test images\n",
        "\n",
        "\n",
        "# 1) Where your test images live\n",
        "test_img_dir  = '/kaggle/input/figs-braintumor-segmentation-classification-sorted/restructured_dataset/segmentation_task/test/images'\n",
        "\n",
        "# 2) Pick a few filenames you want to run\n",
        "sample_files = [\n",
        "    'glioma_1841.jpg',\n",
        "    'meningioma_102.jpg',\n",
        "    'pituitary_1071.jpg'\n",
        "]\n",
        "\n",
        "# 3) Reverse map from class‐index back to name\n",
        "class_map_inv = {0:'glioma', 1:'meningioma', 2:'pituitary'}\n",
        "\n",
        "for fname in sample_files:\n",
        "    img_path = os.path.join(test_img_dir, fname)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Could not read {fname}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # 4) Preprocess\n",
        "    img_resized = cv2.resize(img, (256,256)) / 255.0\n",
        "    inp = img_resized.astype(np.float32)[..., np.newaxis]       # shape (256,256,1)\n",
        "    inp_batch = np.expand_dims(inp, 0)                          # shape (1,256,256,1)\n",
        "\n",
        "    # 5) Predict\n",
        "    seg_pred, cls_pred = best_model.predict(inp_batch, verbose=0)\n",
        "    seg_mask = (seg_pred[0,...,0] > 0.5).astype(np.uint8)       # threshold at 0.5\n",
        "\n",
        "    cls_idx  = np.argmax(cls_pred[0])\n",
        "    cls_conf = cls_pred[0, cls_idx]\n",
        "    cls_name = class_map_inv[cls_idx]\n",
        "\n",
        "    print(f\"{fname}  →  Predicted class: {cls_name} ({cls_conf:.3f})\")\n",
        "\n",
        "    # 6) Visualize\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img_resized, cmap='gray')\n",
        "    plt.title('Input')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(seg_mask, cmap='gray')\n",
        "    plt.title('Predicted Mask')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T19:15:10.151089Z",
          "iopub.execute_input": "2025-08-01T19:15:10.151811Z",
          "iopub.status.idle": "2025-08-01T19:15:10.206047Z",
          "shell.execute_reply.started": "2025-08-01T19:15:10.151788Z",
          "shell.execute_reply": "2025-08-01T19:15:10.205062Z"
        },
        "id": "Ka_djuhDr4Tg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /kaggle/working/*"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-29T09:33:39.283889Z",
          "iopub.execute_input": "2025-07-29T09:33:39.284727Z",
          "iopub.status.idle": "2025-07-29T09:33:39.481215Z",
          "shell.execute_reply.started": "2025-07-29T09:33:39.284703Z",
          "shell.execute_reply": "2025-07-29T09:33:39.480316Z"
        },
        "id": "8jihxQb_r4Th"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}